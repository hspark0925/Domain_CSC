
  0%|                                                                                                                                    | 0/20 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 118, in <module>
    train()
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 115, in train
    trainer.train()
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/trainer.py", line 1938, in train
    return inner_training_loop(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/trainer.py", line 2279, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/trainer.py", line 3318, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/trainer.py", line 3363, in compute_loss
    outputs = model(**inputs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1899, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/peft/peft_model.py", line 1577, in forward
    return self.base_model(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 188, in forward
    return self.model.forward(*args, **kwargs)
  File "/tmp/home/.cache/huggingface/modules/transformers_modules/baichuan-inc/Baichuan2-13B-Chat/09464ad0452a7f4ce69612e4a0147ab853c5fd69/modeling_baichuan.py", line 693, in forward
    outputs = self.model(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/tmp/home/.cache/huggingface/modules/transformers_modules/baichuan-inc/Baichuan2-13B-Chat/09464ad0452a7f4ce69612e4a0147ab853c5fd69/modeling_baichuan.py", line 460, in forward
    layer_outputs = torch.utils.checkpoint.checkpoint(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 249, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 107, in forward
    outputs = run_function(*args)
  File "/tmp/home/.cache/huggingface/modules/transformers_modules/baichuan-inc/Baichuan2-13B-Chat/09464ad0452a7f4ce69612e4a0147ab853c5fd69/modeling_baichuan.py", line 456, in custom_forward
    return module(*inputs, output_attentions, None)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/tmp/home/.cache/huggingface/modules/transformers_modules/baichuan-inc/Baichuan2-13B-Chat/09464ad0452a7f4ce69612e4a0147ab853c5fd69/modeling_baichuan.py", line 241, in forward
    hidden_states = self.input_layernorm(hidden_states)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    result = hook(self, args)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 275, in _pre_forward_module_hook
    self.pre_sub_module_forward_function(module)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/zero/parameter_offload.py", line 449, in pre_sub_module_forward_function
    param_coordinator.fetch_sub_module(sub_module, forward=True)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 310, in fetch_sub_module
    self.__inflight_param_registry.pop(param).wait()
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 724, in wait
    handle.wait()
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 705, in wait
    param.data = instrument_w_nvtx(torch.cat)(partitions).view(param.ds_shape)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 300.00 MiB (GPU 0; 23.65 GiB total capacity; 21.73 GiB already allocated; 210.44 MiB free; 22.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF