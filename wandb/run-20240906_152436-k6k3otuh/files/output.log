

  5%|██████▏                                                                                                                     | 1/20 [01:54<36:10, 114.23s/it]

 10%|████████████▍                                                                                                               | 2/20 [03:43<33:23, 111.33s/it]

 15%|██████████████████▌                                                                                                         | 3/20 [05:33<31:24, 110.84s/it]

 20%|████████████████████████▊                                                                                                   | 4/20 [07:23<29:27, 110.47s/it]
[2024-09-06 15:32:15,324] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912

 25%|███████████████████████████████                                                                                             | 5/20 [09:13<27:34, 110.29s/it]

 30%|█████████████████████████████████████▏                                                                                      | 6/20 [11:03<25:41, 110.09s/it]
[2024-09-06 15:35:54,993] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728


 40%|█████████████████████████████████████████████████▌                                                                          | 8/20 [14:41<21:53, 109.46s/it]
[2024-09-06 15:39:32,891] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 3.71}


 50%|█████████████████████████████████████████████████████████████▌                                                             | 10/20 [18:20<18:15, 109.54s/it]

 55%|███████████████████████████████████████████████████████████████████▋                                                       | 11/20 [20:10<16:27, 109.75s/it]

 60%|█████████████████████████████████████████████████████████████████████████▊                                                 | 12/20 [22:00<14:38, 109.79s/it]
[2024-09-06 15:46:52,237] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152

 65%|███████████████████████████████████████████████████████████████████████████████▉                                           | 13/20 [23:50<12:49, 109.96s/it]

 70%|██████████████████████████████████████████████████████████████████████████████████████                                     | 14/20 [25:40<10:59, 109.87s/it]

 75%|████████████████████████████████████████████████████████████████████████████████████████████▎                              | 15/20 [27:30<09:09, 109.81s/it]
[2024-09-06 15:52:21,913] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 524288, reducing to 262144
[2024-09-06 15:54:11,632] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072


 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 17/20 [31:08<05:28, 109.44s/it]
[2024-09-06 15:56:00,289] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 131072, reducing to 65536

 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 18/20 [32:58<03:39, 109.51s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [36:37<00:00, 109.44s/it] stage3_gather_16bit_weights_on_model_save=false. Saving the full checkpoint instead, use zero_to_fp32.py to recover weights
Saving model checkpoint to /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20
[2024-09-06 16:01:28,800] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0001, 'epoch': 9.28}
loading configuration file config.json from cache at /tmp/home/.cache/huggingface/hub/models--Qwen--Qwen2-7B-Instruct/snapshots/f2826a00ceef68f0f2b946d945ecc0477ce4450c/config.json
Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.44.2",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}
[2024-09-06 16:01:34,618] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step20 is about to be saved!
[2024-09-06 16:01:34,637] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-09-06 16:01:34,637] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt...
Repo card metadata block was not found. Setting CardData to empty.
09/06/2024 16:01:39 - WARNING - huggingface_hub.repocard -   Repo card metadata block was not found. Setting CardData to empty.
[2024-09-06 16:01:38,658] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-09-06 16:01:38,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-06 16:01:38,675] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-06 16:01:38,677] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-06 16:01:38,729] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step20 is ready now!
[2024-09-06 16:01:38,770] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step20 is about to be saved!
[2024-09-06 16:01:38,783] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-09-06 16:01:38,783] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-09-06 16:01:39,287] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-09-06 16:01:39,288] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-09-06 16:01:39,298] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-09-06 16:01:39,298] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved /home/piaoxx/piao1/Domain_LLM/checkpoint/domain-csc-20240906152335/checkpoint-20/global_step20/zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-09-06 16:01:39,345] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step20 is ready now!
loading configuration file config.json from cache at /tmp/home/.cache/huggingface/hub/models--Qwen--Qwen2-7B-Instruct/snapshots/f2826a00ceef68f0f2b946d945ecc0477ce4450c/config.json
Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 32768,
  "max_window_layers": 28,
  "model_type": "qwen2",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.44.2",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 152064
}
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [36:53<00:00, 110.68s/it]
{'train_runtime': 2228.967, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.009, 'train_loss': 0.0, 'epoch': 9.28}