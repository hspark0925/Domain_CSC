WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
[2024-09-06 09:55:25,841] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-06 09:55:25,915] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-06 09:55:25,917] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-06 09:55:25,945] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-06 09:55:27,971] [INFO] [comm.py:637:init_distributed] cdb=None
09/06/2024 09:55:27 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 1
[2024-09-06 09:55:28,081] [INFO] [comm.py:637:init_distributed] cdb=None
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 3
[2024-09-06 09:55:28,159] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-09-06 09:55:28,159] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
[2024-09-06 09:55:28,163] [INFO] [comm.py:637:init_distributed] cdb=None
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 2
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/06/2024 09:55:28 - INFO - torch.distributed.distributed_c10d -   Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
09/06/2024 09:55:28 - INFO - __main__ -   Start loading model: baichuan-inc/Baichuan2-13B-Chat
09/06/2024 09:55:28 - INFO - __main__ -   Start loading model: baichuan-inc/Baichuan2-13B-Chat
09/06/2024 09:55:28 - INFO - __main__ -   Start loading model: baichuan-inc/Baichuan2-13B-Chat
09/06/2024 09:55:28 - INFO - __main__ -   Start loading model: baichuan-inc/Baichuan2-13B-Chat
Traceback (most recent call last):
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 116, in <module>
    train()
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 74, in train
    model = AutoModelForCausalLM.from_pretrained(finetune_args.pretrained_model_path,
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 979, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py", line 640, in resolve_trust_remote_code
    raise ValueError(
ValueError: Loading baichuan-inc/Baichuan2-13B-Chat requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
Traceback (most recent call last):
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 116, in <module>
    train()
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 74, in train
    model = AutoModelForCausalLM.from_pretrained(finetune_args.pretrained_model_path,
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 979, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py", line 640, in resolve_trust_remote_code
    raise ValueError(
ValueError: Loading baichuan-inc/Baichuan2-13B-Chat requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
Traceback (most recent call last):
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 116, in <module>
    train()
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 74, in train
    model = AutoModelForCausalLM.from_pretrained(finetune_args.pretrained_model_path,
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 979, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py", line 640, in resolve_trust_remote_code
    raise ValueError(
ValueError: Loading baichuan-inc/Baichuan2-13B-Chat requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
Traceback (most recent call last):
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 116, in <module>
    train()
  File "/home/piaoxx/piao1/Domain_LLM/train_new.py", line 74, in train
    model = AutoModelForCausalLM.from_pretrained(finetune_args.pretrained_model_path,
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 979, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py", line 640, in resolve_trust_remote_code
    raise ValueError(
ValueError: Loading baichuan-inc/Baichuan2-13B-Chat requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 20200) of binary: /home/piaoxx/miniconda3/envs/env/bin/python
Traceback (most recent call last):
  File "/home/piaoxx/miniconda3/envs/env/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.0.1', 'console_scripts', 'torchrun')())
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/piaoxx/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_new.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-09-06_09:55:37
  host      : jupiter
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 20201)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-09-06_09:55:37
  host      : jupiter
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 20202)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-09-06_09:55:37
  host      : jupiter
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 20203)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-09-06_09:55:37
  host      : jupiter
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 20200)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
